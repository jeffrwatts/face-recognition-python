{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Face Database\n",
    "\n",
    "Prepare the database for faces to recognize.\n",
    "\n",
    "Download a data set under a ./data directory.  \n",
    "\n",
    "This example uses Labeled Faces in the Wild (http://vis-www.cs.umass.edu/lfw/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0-rc1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to load GPU Faiss: No module named swigfaiss_gpu\n",
      "Faiss falling back to CPU-only.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "# Checkout facenet to same root directory as this repository.\n",
    "sys.path.append(\"../facenet/src\")\n",
    "import facenet\n",
    "import align.detect_face\n",
    "\n",
    "sys.path.append(\"../faiss\")\n",
    "import faiss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ../facenet/src/align/detect_face.py:210: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From ../facenet/src/align/detect_face.py:212: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "MODEL_FILE = \"./20170512-110547/20170512-110547.pb\"\n",
    "\n",
    "facenet_graph = tf.Graph()\n",
    "with facenet_graph.as_default():\n",
    "    facenet_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(MODEL_FILE, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        facenet_graph_def.ParseFromString(serialized_graph)            \n",
    "        tf.import_graph_def(facenet_graph_def, name='enet')\n",
    "        \n",
    "        sess = tf.Session()\n",
    "        with sess.as_default():\n",
    "            enet = lambda img : sess.run(('enet/embeddings:0'), feed_dict={'enet/input:0':img, 'enet/phase_train:0':False})\n",
    "            pnet, rnet, onet = align.detect_face.create_mtcnn(sess, None)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face Detection constants.\n",
    "MIN_FACE_SIZE = 20                     # minimum size of the face for the MTCNN\n",
    "DETECT_THRESHOLDS = [ 0.6, 0.7, 0.7 ]  # threshold values for the three stages of the MTCNN\n",
    "SCALE_FACTOR = 0.709                   # MTCNN scale factor\n",
    "\n",
    "# Face Embedding constants.\n",
    "INPUT_IMAGE_SIZE = 160\n",
    "\n",
    "# This function normalizes the image before generating the embedding.\n",
    "def run_facenet(image):\n",
    "    image_data = np.around(image/255.0, decimals=12)\n",
    "    image_data = np.expand_dims(image_data, axis=0)\n",
    "    return enet(image_data)\n",
    "\n",
    "def load_image(image_path):\n",
    "    errorMessage = ''\n",
    "    \n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    if (img is None):\n",
    "        errorMessage = '{}: failed to load'.format(image_path)\n",
    "        return None, errorMessage\n",
    "    \n",
    "    height, width, channels = img.shape \n",
    "    \n",
    "    if (channels < 3):\n",
    "        errorMessage = '{}: less than three dimensions'.format(image_path)\n",
    "        return None, errorMessage\n",
    "    \n",
    "    # Remove Alpha\n",
    "    img = img[:,:,0:3]\n",
    "    \n",
    "    # convert to RGB.\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)        \n",
    "        \n",
    "    return img, errorMessage\n",
    "\n",
    "def import_dataset(input_dir, output_dir, log_filename):   \n",
    "    df = None\n",
    "\n",
    "    # Pick up where we left off if we had to kill the process as it was loading.\n",
    "    if os.path.exists(\"faces.csv\"):\n",
    "        df = pd.read_csv(\"faces.csv\")\n",
    "\n",
    "    output_dir = os.path.expanduser(output_dir)\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    dataset = facenet.get_dataset(input_dir)\n",
    "    \n",
    "    log_file = open(os.path.join(output_dir, log_filename), \"w\")\n",
    "    \n",
    "    images_total = 0\n",
    "    successfully_aligned = 0\n",
    "    \n",
    "    for cls in dataset:\n",
    "        output_class_dir = os.path.join(output_dir, cls.name)\n",
    "        \n",
    "        if not os.path.exists(output_class_dir):\n",
    "            os.makedirs(output_class_dir)\n",
    "        \n",
    "        for image_path in cls.image_paths:\n",
    "            images_total += 1\n",
    "            filename = os.path.splitext(os.path.split(image_path)[1])[0]\n",
    "            output_filename = os.path.join(output_class_dir, filename+'.png')\n",
    "            \n",
    "            print(image_path)\n",
    "            \n",
    "            if not os.path.exists(output_filename):\n",
    "                img, errorMessage = load_image(image_path)\n",
    "\n",
    "                if (img is None):\n",
    "                    print(errorMessage)\n",
    "                    log_file.write(errorMessage)\n",
    "                    continue\n",
    "\n",
    "                bounding_boxes, _ = align.detect_face.detect_face(img, MIN_FACE_SIZE, pnet, rnet, onet, DETECT_THRESHOLDS, SCALE_FACTOR)\n",
    "                \n",
    "                faces = bounding_boxes.shape[0]\n",
    "                \n",
    "                if faces>0:\n",
    "                    det = bounding_boxes[:,0:4]\n",
    "                    det_arr = []\n",
    "                    img_size = np.asarray(img.shape)[0:2]\n",
    "                    if faces>1:\n",
    "                        bounding_box_size = (det[:,2]-det[:,0])*(det[:,3]-det[:,1])\n",
    "                        img_center = img_size / 2\n",
    "                        offsets = np.vstack([ (det[:,0]+det[:,2])/2-img_center[1], (det[:,1]+det[:,3])/2-img_center[0] ])\n",
    "                        offset_dist_squared = np.sum(np.power(offsets,2.0),0)\n",
    "                        index = np.argmax(bounding_box_size-offset_dist_squared*2.0) # some extra weight on the centering\n",
    "                        det_arr.append(det[index,:])\n",
    "                    else:\n",
    "                        det_arr.append(np.squeeze(det))\n",
    "\n",
    "                    for i, det in enumerate(det_arr):\n",
    "                        det = np.squeeze(det)\n",
    "                        bb = np.zeros(4, dtype=np.int32)\n",
    "                        bb[0] = np.maximum(det[0], 0)\n",
    "                        bb[1] = np.maximum(det[1], 0)\n",
    "                        bb[2] = np.minimum(det[2], img_size[1])\n",
    "                        bb[3] = np.minimum(det[3], img_size[0])\n",
    "                        cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\n",
    "                        scaled = cv2.resize(cropped, (INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE), interpolation=cv2.INTER_LINEAR) \n",
    "                        embedding = run_facenet(scaled)\n",
    "\n",
    "                        df1 = pd.DataFrame([cls.name], columns=[\"id\"])\n",
    "                        df2 = pd.DataFrame(embedding)\n",
    "                        row = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "                        if (df is None):\n",
    "                            df = row\n",
    "                        else:\n",
    "                            df = df.append(row)\n",
    "\n",
    "                        df.to_csv(\"faces.csv\", index=False)\n",
    "\n",
    "                        successfully_aligned += 1\n",
    "                        filename_base, file_extension = os.path.splitext(output_filename)                                \n",
    "                        output_filename_n = \"{}{}\".format(filename_base, file_extension)\n",
    "                        scaled = cv2.cvtColor(scaled, cv2.COLOR_RGB2BGR)\n",
    "                        cv2.imwrite(output_filename_n,scaled)\n",
    "                else:\n",
    "                    errorMessage = '{}: no faces'.format(image_path)\n",
    "                    print(errorMessage)\n",
    "                    log_file.write(errorMessage)\n",
    "    \n",
    "    print('Total number of images: %d' % images_total)\n",
    "    print('Number of successfully aligned images: %d' % successfully_aligned)\n",
    "    log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/lfw/AJ_Cook/AJ_Cook_0001.jpg\n",
      "./data/lfw/AJ_Lamas/AJ_Lamas_0001.jpg\n",
      "./data/lfw/Aaron_Eckhart/Aaron_Eckhart_0001.jpg\n",
      "./data/lfw/Aaron_Guiel/Aaron_Guiel_0001.jpg\n",
      "./data/lfw/Aaron_Patterson/Aaron_Patterson_0001.jpg\n",
      "./data/lfw/Aaron_Peirsol/Aaron_Peirsol_0001.jpg\n",
      "./data/lfw/Aaron_Peirsol/Aaron_Peirsol_0002.jpg\n",
      "./data/lfw/Aaron_Peirsol/Aaron_Peirsol_0003.jpg\n",
      "./data/lfw/Aaron_Peirsol/Aaron_Peirsol_0004.jpg\n",
      "./data/lfw/Aaron_Pena/Aaron_Pena_0001.jpg\n",
      "./data/lfw/Aaron_Sorkin/Aaron_Sorkin_0001.jpg\n",
      "./data/lfw/Aaron_Sorkin/Aaron_Sorkin_0002.jpg\n",
      "./data/lfw/Aaron_Tippin/Aaron_Tippin_0001.jpg\n",
      "./data/lfw/Abba_Eban/Abba_Eban_0001.jpg\n",
      "./data/lfw/Abbas_Kiarostami/Abbas_Kiarostami_0001.jpg\n",
      "./data/lfw/Abdel_Aziz_Al-Hakim/Abdel_Aziz_Al-Hakim_0001.jpg\n",
      "./data/lfw/Abdel_Madi_Shabneh/Abdel_Madi_Shabneh_0001.jpg\n",
      "./data/lfw/Abdel_Nasser_Assidi/Abdel_Nasser_Assidi_0001.jpg\n",
      "./data/lfw/Abdel_Nasser_Assidi/Abdel_Nasser_Assidi_0002.jpg\n",
      "./data/lfw/Abdoulaye_Wade/Abdoulaye_Wade_0001.jpg\n",
      "./data/lfw/Abdoulaye_Wade/Abdoulaye_Wade_0002.jpg\n",
      "./data/lfw/Abdoulaye_Wade/Abdoulaye_Wade_0003.jpg\n",
      "./data/lfw/Abdoulaye_Wade/Abdoulaye_Wade_0004.jpg\n",
      "./data/lfw/Abdul_Majeed_Shobokshi/Abdul_Majeed_Shobokshi_0001.jpg\n",
      "./data/lfw/Abdul_Rahman/Abdul_Rahman_0001.jpg\n",
      "./data/lfw/Abdulaziz_Kamilov/Abdulaziz_Kamilov_0001.jpg\n",
      "./data/lfw/Abdullah/Abdullah_0001.jpg\n",
      "./data/lfw/Abdullah/Abdullah_0002.jpg\n",
      "./data/lfw/Abdullah/Abdullah_0003.jpg\n",
      "./data/lfw/Abdullah/Abdullah_0004.jpg\n",
      "./data/lfw/Abdullah_Ahmad_Badawi/Abdullah_Ahmad_Badawi_0001.jpg\n",
      "./data/lfw/Abdullah_Gul/Abdullah_Gul_0001.jpg\n",
      "./data/lfw/Abdullah_Gul/Abdullah_Gul_0002.jpg\n",
      "./data/lfw/Abdullah_Gul/Abdullah_Gul_0003.jpg\n",
      "./data/lfw/Abdullah_Gul/Abdullah_Gul_0004.jpg\n",
      "./data/lfw/Abdullah_Gul/Abdullah_Gul_0005.jpg\n",
      "./data/lfw/Abdullah_Gul/Abdullah_Gul_0006.jpg\n",
      "./data/lfw/Abdullah_Gul/Abdullah_Gul_0007.jpg\n",
      "./data/lfw/Abdullah_Gul/Abdullah_Gul_0008.jpg\n",
      "./data/lfw/Abdullah_Gul/Abdullah_Gul_0009.jpg\n",
      "./data/lfw/Abdullah_Gul/Abdullah_Gul_0010.jpg\n",
      "./data/lfw/Abdullah_Gul/Abdullah_Gul_0011.jpg\n",
      "./data/lfw/Abdullah_Gul/Abdullah_Gul_0012.jpg\n",
      "./data/lfw/Abdullah_Gul/Abdullah_Gul_0013.jpg\n",
      "./data/lfw/Abdullah_Gul/Abdullah_Gul_0014.jpg\n",
      "./data/lfw/Abdullah_Gul/Abdullah_Gul_0015.jpg\n",
      "./data/lfw/Abdullah_Gul/Abdullah_Gul_0016.jpg\n",
      "./data/lfw/Abdullah_Gul/Abdullah_Gul_0017.jpg\n",
      "./data/lfw/Abdullah_Gul/Abdullah_Gul_0018.jpg\n",
      "./data/lfw/Abdullah_Gul/Abdullah_Gul_0019.jpg\n",
      "./data/lfw/Abdullah_Nasseef/Abdullah_Nasseef_0001.jpg\n",
      "./data/lfw/Abdullah_al-Attiyah/Abdullah_al-Attiyah_0001.jpg\n",
      "./data/lfw/Abdullah_al-Attiyah/Abdullah_al-Attiyah_0002.jpg\n",
      "./data/lfw/Abdullah_al-Attiyah/Abdullah_al-Attiyah_0003.jpg\n",
      "./data/lfw/Abdullatif_Sener/Abdullatif_Sener_0001.jpg\n",
      "./data/lfw/Abdullatif_Sener/Abdullatif_Sener_0002.jpg\n",
      "./data/lfw/Abel_Aguilar/Abel_Aguilar_0001.jpg\n",
      "./data/lfw/Abel_Pacheco/Abel_Pacheco_0001.jpg\n",
      "./data/lfw/Abel_Pacheco/Abel_Pacheco_0002.jpg\n",
      "./data/lfw/Abel_Pacheco/Abel_Pacheco_0003.jpg\n",
      "./data/lfw/Abel_Pacheco/Abel_Pacheco_0004.jpg\n",
      "./data/lfw/Abid_Hamid_Mahmud_Al-Tikriti/Abid_Hamid_Mahmud_Al-Tikriti_0001.jpg\n",
      "./data/lfw/Abid_Hamid_Mahmud_Al-Tikriti/Abid_Hamid_Mahmud_Al-Tikriti_0002.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-471c226f4037>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./data/lfw\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./data/lfw-test-output\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimport_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"logfile.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-9d289abd5671>\u001b[0m in \u001b[0;36mimport_dataset\u001b[0;34m(input_dir, output_dir, log_filename)\u001b[0m\n\u001b[1;32m     76\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mbounding_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_face\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMIN_FACE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDETECT_THRESHOLDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSCALE_FACTOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbounding_boxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jewatts/TensorflowProjects/git/facenet/src/align/detect_face.pyc\u001b[0m in \u001b[0;36mdetect_face\u001b[0;34m(img, minsize, pnet, rnet, onet, threshold, factor)\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0medy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0medx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m                 \u001b[0mtempimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m48\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jewatts/TensorflowProjects/git/facenet/src/align/detect_face.pyc\u001b[0m in \u001b[0;36mimresample\u001b[0;34m(img, sz)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m     \u001b[0mim_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_AREA\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#@UndefinedVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mim_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_dir = \"./data/lfw\"\n",
    "output_dir = \"./data/lfw-test-output\"\n",
    "import_dataset(input_dir, output_dir, \"logfile.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification\n",
    "\n",
    "These code blocks are meant to verify if any refactoring to import_dataset has changed current behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset to verify against.\n",
    "df_test = pd.read_csv(\"faces_cv2.csv\")\n",
    "\n",
    "face_identities = []\n",
    "face_index = faiss.IndexFlatL2(128)\n",
    "\n",
    "for _, row in df_test.iterrows():\n",
    "    identity = row['id']\n",
    "    embedding = row.iloc[1:129].as_matrix().astype('float32')\n",
    "    embedding = np.ascontiguousarray(embedding.reshape(1, 128))\n",
    "    face_index.add(embedding)\n",
    "    face_identities.append(identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   10    11]\n",
      " [   11    10]\n",
      " [   12  7152]\n",
      " [   13  1925]\n",
      " [   14  1019]\n",
      " [   15  5096]\n",
      " [   16 11343]\n",
      " [   17    18]\n",
      " [   18    17]\n",
      " [   19    22]\n",
      " [   20    22]\n",
      " [   21  1906]\n",
      " [   22    20]\n",
      " [   23   780]\n",
      " [   24  7687]]\n",
      "[[0.         0.719885  ]\n",
      " [0.         0.719885  ]\n",
      " [0.         0.8338822 ]\n",
      " [0.         0.58752376]\n",
      " [0.         0.80528855]\n",
      " [0.         0.6336254 ]\n",
      " [0.         0.8650813 ]\n",
      " [0.         0.14895748]\n",
      " [0.         0.14895748]\n",
      " [0.         0.48159125]\n",
      " [0.         0.29430538]\n",
      " [0.         0.35350424]\n",
      " [0.         0.29430538]\n",
      " [0.         0.8343713 ]\n",
      " [0.         0.7308166 ]]\n",
      "Aaron_Sorkin\n",
      "Aaron_Sorkin\n",
      "Aaron_Tippin\n",
      "Abba_Eban\n",
      "Abbas_Kiarostami\n",
      "Abdel_Aziz_Al-Hakim\n",
      "Abdel_Madi_Shabneh\n",
      "Abdel_Nasser_Assidi\n",
      "Abdel_Nasser_Assidi\n",
      "Abdoulaye_Wade\n",
      "Abdoulaye_Wade\n",
      "Abdoulaye_Wade\n",
      "Abdoulaye_Wade\n",
      "Abdul_Majeed_Shobokshi\n",
      "Abdul_Rahman\n"
     ]
    }
   ],
   "source": [
    "# Verify the results are the same.  Note comparing more than 15 faces at a time will not yield the exact result.\n",
    "OFFSET=10\n",
    "TEST_FACES = 15\n",
    "\n",
    "df_test = pd.read_csv(\"faces.csv\")\n",
    "\n",
    "embeddings = np.zeros((TEST_FACES, 128), dtype=np.float32)\n",
    "\n",
    "for index, row in df_test.iterrows():\n",
    "    adjusted_index = index - OFFSET\n",
    "    \n",
    "    if (adjusted_index == TEST_FACES):\n",
    "        break\n",
    "        \n",
    "    if (adjusted_index >= 0):\n",
    "        embedding = row.iloc[1:129].as_matrix().astype('float32')\n",
    "        embeddings[adjusted_index,:] = np.ascontiguousarray(embedding.reshape(1, 128))\n",
    "    \n",
    "\n",
    "distances, indicies = face_index.search(embeddings, 2)\n",
    "print(indicies)\n",
    "print(distances)\n",
    "\n",
    "for ix in range(len(indicies)):\n",
    "    print(face_identities[indicies[ix,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
